{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from transformers import *\n",
    "import torch.optim as optim\n",
    "from sst_classifier import LstmClassifier\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "from allennlp.data.dataset_readers.stanford_sentiment_tree_bank import StanfordSentimentTreeBankDatasetReader\n",
    "from allennlp.data.iterators import BucketIterator, BasicIterator\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders.embedding import _read_pretrained_embeddings_file\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.nn.util import get_text_field_mask, move_to_device\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.gradcheck import zero_gradients\n",
    "import torch.nn.functional as F\n",
    "sys.path.append('../')\n",
    "from ARAE_utils import Seq2Seq, MLP_D, MLP_G, generate\n",
    "from utils import get_embedding_weight, get_accuracy\n",
    "from attack_util import project_noise, one_hot_prob, GPT2_LM_loss, select_fluent_trigger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ARAE_models(load_path, args):\n",
    "    # function to load ARAE model.\n",
    "    if not os.path.exists(load_path):\n",
    "        print('Please download the pretrained ARAE model first')\n",
    "        \n",
    "    ARAE_args = json.load(open(os.path.join(load_path, 'options.json'), 'r'))\n",
    "    vars(args).update(ARAE_args)\n",
    "    autoencoder = Seq2Seq(emsize=args.emsize,\n",
    "                          nhidden=args.nhidden,\n",
    "                          ntokens=args.ntokens,\n",
    "                          nlayers=args.nlayers,\n",
    "                          noise_r=args.noise_r,\n",
    "                          hidden_init=args.hidden_init,\n",
    "                          dropout=args.dropout,\n",
    "                          gpu=args.cuda)\n",
    "    gan_gen = MLP_G(ninput=args.z_size, noutput=args.nhidden, layers=args.arch_g)\n",
    "    gan_disc = MLP_D(ninput=args.nhidden, noutput=1, layers=args.arch_d)\n",
    "\n",
    "    autoencoder = autoencoder.cuda()\n",
    "    gan_gen = gan_gen.cuda()\n",
    "    gan_disc = gan_disc.cuda()\n",
    "\n",
    "    ARAE_word2idx = json.load(open(os.path.join(args.load_path, 'vocab.json'), 'r'))\n",
    "    ARAE_idx2word = {v: k for k, v in ARAE_word2idx.items()}\n",
    "\n",
    "    print('Loading models from {}'.format(args.load_path))\n",
    "    loaded = torch.load(os.path.join(args.load_path, \"model.pt\"))\n",
    "    autoencoder.load_state_dict(loaded.get('ae'))\n",
    "    gan_gen.load_state_dict(loaded.get('gan_g'))\n",
    "    gan_disc.load_state_dict(loaded.get('gan_d'))\n",
    "    return ARAE_args, ARAE_idx2word, ARAE_word2idx, autoencoder, gan_gen, gan_disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--load_path', type=str, default='../../ARAE/sentiment_classifier/oneb_pretrained',\n",
    "                    help='directory to load models from')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--sample', action='store_true',\n",
    "                    help='sample when decoding for generation')\n",
    "parser.add_argument('--len_lim', type=int, default=5,\n",
    "                    help='maximum length of sentence')\n",
    "parser.add_argument('--r_lim', type=float, default=1,\n",
    "                    help='lim of radius of z')\n",
    "parser.add_argument('--sentiment_path', type=str, default='./opinion_lexicon_English',\n",
    "                    help='directory to load sentiment word from')\n",
    "parser.add_argument('--z_seed', type=float, default=6.,\n",
    "                    help='noise seed for z')\n",
    "parser.add_argument('--avoid_l', type=int, default=4,\n",
    "                    help='length to avoid repeated pattern')\n",
    "parser.add_argument('--lr', type=float, default=1e3,\n",
    "                    help='learn rate')\n",
    "parser.add_argument('--attack_class', type=str, default='1',\n",
    "                    help='the class label to attack')\n",
    "parser.add_argument('--noise_n', type=int, default=256,\n",
    "                    help='number of generated noise vectors')\n",
    "parser.add_argument('--tot_runs', type=int, default=1,\n",
    "                    help='number of attack runs')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ARAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from ../../ARAE/sentiment_classifier/oneb_pretrained\n"
     ]
    }
   ],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# initialize ARAE model.\n",
    "ARAE_args, ARAE_idx2word, ARAE_word2idx, autoencoder, gan_gen, gan_disc = load_ARAE_models(args.load_path, args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LstmClassifier(\n",
       "  (word_embeddings): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (encoder): PytorchSeq2VecWrapper(\n",
       "    (_module): LSTM(300, 512, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (loss_function): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained sentiment analysis model.\n",
    "word_embedding_dim = 300\n",
    "EMBEDDING_TYPE = \"w2v\"\n",
    "vocab_path = \"./model_dir/\" + EMBEDDING_TYPE + \"_\" + \"vocab\"\n",
    "\n",
    "sst_vocab = Vocabulary.from_files(vocab_path)\n",
    "weight = torch.load('sst_emb_weight.pt')\n",
    "token_embedding = Embedding(num_embeddings=sst_vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=word_embedding_dim,\n",
    "                            weight=weight,\n",
    "                            trainable=False)\n",
    "\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "encoder = PytorchSeq2VecWrapper(torch.nn.LSTM(word_embedding_dim,\n",
    "                                              hidden_size=512,\n",
    "                                              num_layers=2,\n",
    "                                              batch_first=True))\n",
    "\n",
    "model_path = \"./model_dir/\" + EMBEDDING_TYPE + \"_\" + \"model.th\"\n",
    "model = LstmClassifier(word_embeddings, encoder, sst_vocab)\n",
    "\n",
    "with open(model_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    f.close()\n",
    "embedding_weight = get_embedding_weight(model)\n",
    "model.train().cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ARAE word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arange ARAE word embedding in consistent with sst model.\n",
    "ARAE_weight_embedding = []\n",
    "for num in range(len(ARAE_idx2word)):\n",
    "    ARAE_weight_embedding.append(embedding_weight[sst_vocab.get_token_index(ARAE_idx2word[num])].numpy())\n",
    "ARAE_weight_embedding = torch.from_numpy(np.array(ARAE_weight_embedding)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove sentiment words from ARAE so that we won't use them to generate trivial attacks. Also, mask out the unkown words for SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "872it [00:00, 1373.39it/s]\n"
     ]
    }
   ],
   "source": [
    "### collect positive/negative sentences\n",
    "single_id_indexer = SingleIdTokenIndexer(lowercase_tokens=True)  # word tokenizer\n",
    "reader = StanfordSentimentTreeBankDatasetReader(granularity=\"2-class\",\n",
    "                                                token_indexers={\"tokens\": single_id_indexer})\n",
    "dev_data = reader.read('https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt')\n",
    "\n",
    "# For sentiment analysis, get rid of positive and negative.\n",
    "pos_path = os.path.join(args.sentiment_path, 'positive_words.txt')\n",
    "neg_path = os.path.join(args.sentiment_path, 'negative_words.txt')\n",
    "\n",
    "pos_words = list()\n",
    "with open(cached_path(pos_path), \"r\") as data_file:\n",
    "    for line in data_file.readlines():\n",
    "        if line[0] != ';':\n",
    "            line = line.strip(\"\\n\")\n",
    "            if not line:\n",
    "                continue\n",
    "            else:\n",
    "                pos_words.append(line)\n",
    "\n",
    "neg_words = list()\n",
    "with open(cached_path(neg_path), \"r\", encoding = \"ISO-8859-1\") as data_file:\n",
    "    for line in data_file.readlines():\n",
    "        if line[0] != ';':\n",
    "            line = line.strip(\"\\n\")\n",
    "            if not line:\n",
    "                continue\n",
    "            else:\n",
    "                neg_words.append(line)\n",
    "\n",
    "my_list = ['missing', 'rapes']\n",
    "sentiment_words = pos_words + neg_words + my_list\n",
    "\n",
    "mask_word_ARAE = list()\n",
    "for word in sentiment_words:\n",
    "    if word in ARAE_word2idx:\n",
    "        mask_word_ARAE.append(ARAE_word2idx[word])\n",
    "\n",
    "# mask words that are unknown for sentiment words.\n",
    "ARAE_words = list(ARAE_word2idx.keys())\n",
    "for word in ARAE_words:\n",
    "    if sst_vocab.get_token_index(word) == 1:\n",
    "        mask_word_ARAE.append(ARAE_word2idx[word])\n",
    "mask_word_ARAE = list(set(mask_word_ARAE))\n",
    "sent_word_ARAE = np.array(mask_word_ARAE)\n",
    "\n",
    "mask_sentiment_logits = np.zeros((1, 1, len(ARAE_words)))\n",
    "mask_sentiment_logits[:, :, sent_word_ARAE] = -float(\"Inf\")\n",
    "mask_sentiment_logits = torch.tensor(mask_sentiment_logits, requires_grad=False)\n",
    "mask_sentiment_logits = mask_sentiment_logits.float().cuda()\n",
    "mask_sentiment = mask_sentiment_logits[0]\n",
    "\n",
    "dataset_label_filter = args.attack_class\n",
    "targeted_dev_data = []\n",
    "\n",
    "for instance in dev_data:\n",
    "    if instance['label'].label == dataset_label_filter:\n",
    "        targeted_dev_data.append(instance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to generate universal trigger to attack the sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_seed:6.0\n",
      "current iter:100\n",
      "current loss:0.639477762579918\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:200\n",
      "current loss:0.8375141072273254\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:300\n",
      "current loss:0.9308520996570587\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:400\n",
      "current loss:1.0014018946886063\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:500\n",
      "current loss:1.0514321714639663\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:600\n",
      "current loss:1.1014188688993454\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:700\n",
      "current loss:1.154832775592804\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:800\n",
      "current loss:1.1843047964572906\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:900\n",
      "current loss:1.2190979808568954\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:1000\n",
      "current loss:1.2490628385543823\n",
      "current patience:0\n",
      "\n",
      "\n",
      "a flat explosion empty over 0.2635135135135135 9.2433500289917\n",
      "five drowned holes to shoot 0.30405405405405406 9.351275444030762\n",
      "shut down 1 empty cell 0.3063063063063063 7.146684646606445\n",
      "seven holes shut down 3 0.30855855855855857 7.695056915283203\n",
      "=== best trigger is \"  shut down 1 empty cell  \" with model accuracy  0.3063063063063063\n"
     ]
    }
   ],
   "source": [
    "model.get_metrics(reset=True)\n",
    "\n",
    "iterator = BucketIterator(batch_size=256, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(sst_vocab)\n",
    "get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids=None)\n",
    "\n",
    "\n",
    "maxlen = args.len_lim\n",
    "# initialize noise\n",
    "noise_n = args.noise_n  # this should be a factor of batch_size\n",
    "tot_runs = args.tot_runs\n",
    "n_repeat = 1\n",
    "\n",
    "\n",
    "r_threshold = args.r_lim\n",
    "step_bound = r_threshold / 100\n",
    "max_iterations = 1000\n",
    "\n",
    "patience_lim = 3\n",
    "patience = 0 \n",
    "max_trial = 3\n",
    "all_output = list()\n",
    "log_loss = int(1e2)\n",
    "\n",
    "for tmp in range(tot_runs):\n",
    "    model.get_metrics(reset=True)\n",
    "    step_size = args.lr\n",
    "    step_scale = 0.1 \n",
    "    patience = 0\n",
    "    old_noise = None\n",
    "    old_loss = float('-Inf')\n",
    "    loss_list = list()\n",
    "    update = False\n",
    "    i_trial = 0\n",
    "\n",
    "    torch.manual_seed(args.z_seed + tmp)\n",
    "    print('z_seed:{}'.format(args.z_seed + tmp))\n",
    "    noise = torch.randn(noise_n, ARAE_args['z_size'], requires_grad=True).cuda()\n",
    "    noise = Variable(noise, requires_grad=True)\n",
    "    start_noise_data = noise.data.clone()\n",
    "    iter = 0\n",
    "    for batch in lazy_groups_of(iterator(targeted_dev_data, num_epochs=int(5e5), shuffle=True), group_size=1):\n",
    "        # evaluate_batch(model, batch, trigger_token_ids, snli)\n",
    "        # generate sentence with ARAE, output the word embedding instead of index.\n",
    "        batch = move_to_device(batch[0], cuda_device=0)\n",
    "        tokens = batch['tokens']\n",
    "        label = batch['label']\n",
    "\n",
    "        model.train()\n",
    "        autoencoder.train()\n",
    "        gan_gen.eval()\n",
    "        gan_disc.eval()\n",
    "\n",
    "        hidden = gan_gen(noise)\n",
    "\n",
    "\n",
    "        max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                             mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "        decoded = torch.stack(decoded, dim=1).float()\n",
    "        if n_repeat > 1:\n",
    "            decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "        decoded_prob = F.softmax(decoded, dim=-1)\n",
    "        decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "        out_emb = torch.matmul(decoded_prob, ARAE_weight_embedding)\n",
    "        output = model.forward_with_trigger(out_emb, tokens, label)\n",
    "\n",
    "        loss = output[\"loss\"]\n",
    "        iter += 1\n",
    "\n",
    "        loss_list.append(output[\"loss\"].item())\n",
    "        zero_gradients(noise)\n",
    "        loss.backward()\n",
    "\n",
    "        noise_diff = step_size * noise.grad.data\n",
    "        noise_diff = project_noise(noise_diff, r_threshold=step_bound)\n",
    "\n",
    "        noise.data = noise.data + noise_diff\n",
    "\n",
    "        whole_diff = noise.data - start_noise_data\n",
    "        whole_diff = project_noise(whole_diff, r_threshold=r_threshold)\n",
    "        noise.data = start_noise_data + whole_diff\n",
    "\n",
    "        if iter % log_loss == 0:\n",
    "            cur_loss = np.mean(loss_list)\n",
    "            print('current iter:{}'.format(iter))\n",
    "            print('current loss:{}'.format(cur_loss))\n",
    "\n",
    "            loss_list = list()\n",
    "            if cur_loss > old_loss:\n",
    "                patience = 0\n",
    "                old_loss = cur_loss\n",
    "                old_noise = noise.data.clone()\n",
    "                update = True\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "            print('current patience:{}'.format(patience))\n",
    "            print('\\n')\n",
    "\n",
    "            if patience >= patience_lim:\n",
    "                patience = 0\n",
    "                step_size *= step_scale\n",
    "                noise.data = old_noise\n",
    "                print('current step size:{}'.format(step_size))\n",
    "                i_trial += 1\n",
    "                print('current trial:{}'.format(i_trial))\n",
    "                print('\\n')\n",
    "\n",
    "        if i_trial >= max_trial or iter >= max_iterations:\n",
    "            if update:\n",
    "                with torch.no_grad():\n",
    "                    noise_new = torch.ones(noise_n, ARAE_args['z_size'], requires_grad=False).cuda()\n",
    "                    noise_new.data = old_noise\n",
    "                    hidden = gan_gen(noise_new)  # [:1, :]\n",
    "                    max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                                         mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "                    decoded = torch.stack(decoded, dim=1).float()\n",
    "                    if n_repeat > 1:\n",
    "                        decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "                    decoded_prob = F.softmax(decoded, dim=-1)\n",
    "                    decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "\n",
    "                sen_idxs = torch.argmax(decoded_prob, dim=2)\n",
    "                sen_idxs = sen_idxs.cpu().numpy()\n",
    "\n",
    "                output_s = list()\n",
    "                glue = ' '\n",
    "                sentence_list = list()\n",
    "                for ss in sen_idxs:\n",
    "                    sentence = [ARAE_idx2word[s] for s in ss]\n",
    "                    trigger_token_ids = list()\n",
    "                    last_word = None\n",
    "                    last_word2 = None\n",
    "                    contain_sentiment_word = False\n",
    "                    new_sentence = list()\n",
    "                    for word in sentence:\n",
    "                        cur_idx = sst_vocab.get_token_index(word)\n",
    "                        if cur_idx != last_word and cur_idx != last_word2:\n",
    "                            trigger_token_ids.append(cur_idx)\n",
    "                            new_sentence.append(word)\n",
    "                            last_word2 = last_word\n",
    "                            last_word = cur_idx\n",
    "\n",
    "                            if word in sentiment_words:\n",
    "                                contain_sentiment_word = True\n",
    "\n",
    "                    threshold = 0.5\n",
    "                    num_lim = 20\n",
    "                    s_str = glue.join(new_sentence)\n",
    "                    if not (s_str in sentence_list):\n",
    "                        accuracy = get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids)\n",
    "                        if accuracy < threshold:\n",
    "                            sentence_list.append(s_str)\n",
    "                            output_s.append((s_str, accuracy, contain_sentiment_word))\n",
    "\n",
    "                if len(output_s) > 0:\n",
    "                    all_output = all_output + output_s\n",
    "                update = False\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# use GPT2 for post selection.\n",
    "GPT2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "GPT2_model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "\n",
    "triggers = all_output\n",
    "select_fluent_trigger(triggers, GPT2_model, GPT2_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import logging\n",
    "\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from itertools import chain\n",
    "\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.fields import LabelField, TextField, Field\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Tokenizer, WordTokenizer\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@DatasetReader.register('imdb')\n",
    "class ImdbDatasetReader(DatasetReader):\n",
    "\n",
    "    TAR_URL = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    TRAIN_DIR = 'aclImdb/train'\n",
    "    TEST_DIR = 'aclImdb/test'\n",
    "\n",
    "    def __init__(self,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 lazy: bool = False) -> None:\n",
    "        super().__init__(lazy=lazy)\n",
    "\n",
    "        self._tokenizer = tokenizer or WordTokenizer()\n",
    "        self._token_indexers = token_indexers or {'tokens': SingleIdTokenIndexer()}\n",
    "\n",
    "    @overrides\n",
    "    def _read(self, file_path):\n",
    "        tar_path = cached_path(self.TAR_URL)\n",
    "        tf = tarfile.open(tar_path, 'r')\n",
    "        cache_dir = Path(osp.dirname(tar_path))\n",
    "        if not (cache_dir / self.TRAIN_DIR).exists() and not (cache_dir / self.TEST_DIR).exists():\n",
    "            tf.extractall(cache_dir)\n",
    "\n",
    "        if file_path == 'train':\n",
    "            pos_dir = osp.join(self.TRAIN_DIR, 'pos')\n",
    "            neg_dir = osp.join(self.TRAIN_DIR, 'neg')\n",
    "        elif file_path == 'test':\n",
    "            pos_dir = osp.join(self.TEST_DIR, 'pos')\n",
    "            neg_dir = osp.join(self.TEST_DIR, 'neg')\n",
    "        else:\n",
    "            raise ValueError(f\"only 'train' and 'test' are valid for 'file_path', but '{file_path}' is given.\")\n",
    "        path = chain(Path(cache_dir.joinpath(pos_dir)).glob('*.txt'),\n",
    "                     Path(cache_dir.joinpath(neg_dir)).glob('*.txt'))\n",
    "\n",
    "        for p in path:\n",
    "            yield self.text_to_instance(p.read_text(), 0 if 'pos' in str(p) else 1)\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, string: str, label: int) -> Instance:\n",
    "        fields: Dict[str, Field] = {}\n",
    "        tokens = self._tokenizer.tokenize(string)\n",
    "        fields['tokens'] = TextField(tokens, self._token_indexers)\n",
    "        fields['label'] = LabelField(label, skip_indexing=True)\n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25000it [00:59, 418.38it/s]\n",
      "25000it [00:57, 437.07it/s]\n"
     ]
    }
   ],
   "source": [
    "single_id_indexer = SingleIdTokenIndexer(lowercase_tokens=True)  # word tokenizer\n",
    "reader = ImdbDatasetReader(token_indexers={\"tokens\": single_id_indexer})\n",
    "train_data = reader.read('train')\n",
    "test_data = reader.read('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t tokens: TextField of length 146 with text: \n",
      " \t\t[Zentropa, has, much, in, common, with, The, Third, Man, ,, another, noir, -, like, film, set,\n",
      "\t\tamong, the, rubble, of, postwar, Europe, ., Like, TTM, ,, there, is, much, inventive, camera, work,\n",
      "\t\t., There, is, an, innocent, American, who, gets, emotionally, involved, with, a, woman, he, does,\n",
      "\t\tn't, really, understand, ,, and, whose, naivety, is, all, the, more, striking, in, contrast, with,\n",
      "\t\tthe, natives.<br, /><br, />But, I, 'd, have, to, say, that, The, Third, Man, has, a, more, well, -,\n",
      "\t\tcrafted, storyline, ., Zentropa, is, a, bit, disjointed, in, this, respect, ., Perhaps, this, is,\n",
      "\t\tintentional, :, it, is, presented, as, a, dream, /, nightmare, ,, and, making, it, too, coherent,\n",
      "\t\twould, spoil, the, effect, ., <, br, /><br, />This, movie, is, unrelentingly, grim--\"noir, \", in,\n",
      "\t\tmore, than, one, sense, ;, one, never, sees, the, sun, shine, ., Grim, ,, but, intriguing, ,, and,\n",
      "\t\tfrightening, .]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t label: LabelField with label: 0 in namespace: 'labels'.' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the instances of IMDB dataset; train and test data have both 250000 instances, \n",
    "## first half of data (0~12499) has label 0, and the rest has label 1\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment classification for IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8072"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Without attack, measure accuracy for positive class (label=0)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, train_data[0:12500][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, train_data[0:12500][::downsample_rate], sst_vocab, trigger_token_ids=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6824"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Without attack, measure accuracy for positive class (label=1)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, train_data[12500:][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, train_data[12500:][::downsample_rate], sst_vocab, trigger_token_ids=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.812"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Without attack, measure accuracy for positive class (label=0)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, test_data[0:12500][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, test_data[0:12500][::downsample_rate], sst_vocab, trigger_token_ids=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6792"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Without attack, measure accuracy for positive class (label=1)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, test_data[12500:][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, test_data[12500:][::downsample_rate], sst_vocab, trigger_token_ids=None)\n",
    "\n",
    "# get_accuracy(model, test_data, sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Trigger Attack with IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 277096.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## collect target dataset\n",
    "from tqdm import tqdm\n",
    "downsample = True\n",
    "args.attack_class = '0'\n",
    "dataset_label_filter = args.attack_class\n",
    "targeted_dev_data = []\n",
    "count = 0\n",
    "for instance in tqdm(test_data, leave=True, position=0):\n",
    "    if str(instance['label'].label) == dataset_label_filter:\n",
    "        targeted_dev_data.append(instance)\n",
    "        count += 1\n",
    "print(count)\n",
    "if downsample:\n",
    "    downsample_rate = 10\n",
    "    targeted_dev_data = targeted_dev_data[::downsample_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250 LabelField with label: 0 in namespace: 'labels'.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.812"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_metrics(reset=True)\n",
    "\n",
    "iterator = BucketIterator(batch_size=256, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(sst_vocab)\n",
    "print(len(targeted_dev_data), targeted_dev_data[0]['label'])\n",
    "get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3620,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 604, 6164,  575,  ...,    0,    0,    0],\n",
      "        [  61,  105,  114,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [1438,   24, 1087,  ..., 2107,    8,    0],\n",
      "        [9578,    1, 2356,  ...,    0,    0,    0],\n",
      "        [  21,  361,    9,  ...,  208,    8,    0]], device='cuda:0') torch.Size([256, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in lazy_groups_of(iterator(targeted_dev_data, num_epochs=int(5e5), shuffle=True), group_size=1):\n",
    "    # evaluate_batch(model, batch, trigger_token_ids, snli)\n",
    "    # generate sentence with ARAE, output the word embedding instead of index.\n",
    "    batch = move_to_device(batch[0], cuda_device=0)\n",
    "    tokens = batch['tokens']\n",
    "    label = batch['label']\n",
    "    print(batch['tokens']['tokens'], model(tokens, label)['logits'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_seed:6.0\n",
      "current iter:100\n",
      "current loss:0.4548827594518661\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:200\n",
      "current loss:0.4578839448094368\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:300\n",
      "current loss:0.45887114137411117\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:400\n",
      "current loss:0.46013588070869443\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:500\n",
      "current loss:0.460807763338089\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:600\n",
      "current loss:0.4617543679475784\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:700\n",
      "current loss:0.4631617853045464\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:800\n",
      "current loss:0.4640642374753952\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:900\n",
      "current loss:0.4644192340970039\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:1000\n",
      "current loss:0.46425241768360137\n",
      "current patience:1\n",
      "\n",
      "\n",
      "three drowned ? screaming naked . out ? 0.7904 8.639504432678223\n",
      "empty plastic seats sit shut out . ? 0.7912 8.194149017333984\n",
      "just plastic windows shut down soon laid off 0.7912 8.003519058227539\n",
      "the left empty off inside bed to empty 0.7912 8.025712013244629\n",
      "media pages claims released document dismissed evidence claims 0.792 9.03561019897461\n",
      "the accident forced air pollution near the existing 0.792 7.761316776275635\n",
      "dry commercial zero dollars . flood rescue forced 0.7936 9.435844421386719\n",
      "the procedure closed down over the wall floor 0.7952 6.87434196472168\n",
      "bottom boots ? off . $ 2 ? 0.7952 7.49782657623291\n",
      "they threw debris and wreckage outside the debris 0.7952 6.749879360198975\n",
      "seven seconds over the empty concrete rooms stopped 0.7952 8.368694305419922\n",
      "it spent $ 1.8 on maintenance . $ 0.7952 7.442106604576111\n",
      "this week forced bankruptcy money to buy government 0.796 7.742929458618164\n",
      "=== best trigger is \"  they threw debris and wreckage outside the debris  \" with model accuracy  0.7952\n"
     ]
    }
   ],
   "source": [
    "model.get_metrics(reset=True)\n",
    "\n",
    "iterator = BucketIterator(batch_size=256, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(sst_vocab)\n",
    "get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids=None)\n",
    "\n",
    "\n",
    "maxlen = 8 # args.len_lim \n",
    "# initialize noise\n",
    "noise_n = args.noise_n  # this should be a factor of batch_size\n",
    "tot_runs = args.tot_runs\n",
    "n_repeat = 1\n",
    "\n",
    "\n",
    "r_threshold = args.r_lim\n",
    "step_bound = r_threshold / 100\n",
    "max_iterations = 1000 \n",
    "\n",
    "patience_lim = 3\n",
    "patience = 0 \n",
    "max_trial = 3\n",
    "all_output = list()\n",
    "log_loss = int(1e2)\n",
    "args.z_seed = 6.0\n",
    "for tmp in range(tot_runs):\n",
    "    model.get_metrics(reset=True)\n",
    "    step_size = args.lr * 1000\n",
    "    step_scale = 0.1 \n",
    "    patience = 0\n",
    "    old_noise = None\n",
    "    old_loss = float('-Inf')\n",
    "    loss_list = list()\n",
    "    update = False\n",
    "    i_trial = 0\n",
    "\n",
    "    torch.manual_seed(args.z_seed + tmp)\n",
    "    print('z_seed:{}'.format(args.z_seed + tmp))\n",
    "    noise = torch.randn(noise_n, ARAE_args['z_size'], requires_grad=True).cuda()\n",
    "    noise = Variable(noise, requires_grad=True)\n",
    "    start_noise_data = noise.data.clone()\n",
    "    iter = 0\n",
    "    for batch in lazy_groups_of(iterator(targeted_dev_data, num_epochs=int(5e5), shuffle=True), group_size=1):\n",
    "        # evaluate_batch(model, batch, trigger_token_ids, snli)\n",
    "        # generate sentence with ARAE, output the word embedding instead of index.\n",
    "        batch = move_to_device(batch[0], cuda_device=0)\n",
    "        tokens = batch['tokens']\n",
    "        label = batch['label']\n",
    "        \n",
    "        model.train()\n",
    "        autoencoder.train()\n",
    "        gan_gen.eval()\n",
    "        gan_disc.eval()\n",
    "\n",
    "        hidden = gan_gen(noise)\n",
    "\n",
    "\n",
    "        max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                             mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "        decoded = torch.stack(decoded, dim=1).float()\n",
    "        if n_repeat > 1:\n",
    "            decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "        decoded_prob = F.softmax(decoded, dim=-1)\n",
    "        decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "        out_emb = torch.matmul(decoded_prob, ARAE_weight_embedding)\n",
    "        output = model.forward_with_trigger(out_emb, tokens, label)\n",
    "\n",
    "        loss = output[\"loss\"]\n",
    "        iter += 1\n",
    "\n",
    "        loss_list.append(output[\"loss\"].item())\n",
    "        zero_gradients(noise)\n",
    "        loss.backward()\n",
    "\n",
    "        noise_diff = step_size * noise.grad.data\n",
    "        noise_diff = project_noise(noise_diff, r_threshold=step_bound)\n",
    "\n",
    "        noise.data = noise.data + noise_diff\n",
    "\n",
    "        whole_diff = noise.data - start_noise_data\n",
    "        whole_diff = project_noise(whole_diff, r_threshold=r_threshold)\n",
    "        noise.data = start_noise_data + whole_diff\n",
    "\n",
    "        if iter % log_loss == 0:\n",
    "            cur_loss = np.mean(loss_list)\n",
    "            print('current iter:{}'.format(iter))\n",
    "            print('current loss:{}'.format(cur_loss))\n",
    "\n",
    "            loss_list = list()\n",
    "            if cur_loss > old_loss:\n",
    "                patience = 0\n",
    "                old_loss = cur_loss\n",
    "                old_noise = noise.data.clone()\n",
    "                update = True\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "            print('current patience:{}'.format(patience))\n",
    "            print('\\n')\n",
    "\n",
    "            if patience >= patience_lim:\n",
    "                patience = 0\n",
    "                step_size *= step_scale\n",
    "                noise.data = old_noise\n",
    "                print('current step size:{}'.format(step_size))\n",
    "                i_trial += 1\n",
    "                print('current trial:{}'.format(i_trial))\n",
    "                print('\\n')\n",
    "\n",
    "        if i_trial >= max_trial or iter >= max_iterations:\n",
    "            if update:\n",
    "                with torch.no_grad():\n",
    "                    noise_new = torch.ones(noise_n, ARAE_args['z_size'], requires_grad=False).cuda()\n",
    "                    noise_new.data = old_noise\n",
    "                    hidden = gan_gen(noise_new)  # [:1, :]\n",
    "                    max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                                         mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "                    decoded = torch.stack(decoded, dim=1).float()\n",
    "                    if n_repeat > 1:\n",
    "                        decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "                    decoded_prob = F.softmax(decoded, dim=-1)\n",
    "                    decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "\n",
    "                sen_idxs = torch.argmax(decoded_prob, dim=2)\n",
    "                sen_idxs = sen_idxs.cpu().numpy()\n",
    "\n",
    "                output_s = list()\n",
    "                glue = ' '\n",
    "                sentence_list = list()\n",
    "                for ss in sen_idxs:\n",
    "                    sentence = [ARAE_idx2word[s] for s in ss]\n",
    "                    trigger_token_ids = list()\n",
    "                    last_word = None\n",
    "                    last_word2 = None\n",
    "                    contain_sentiment_word = False\n",
    "                    new_sentence = list()\n",
    "                    for word in sentence:\n",
    "                        cur_idx = sst_vocab.get_token_index(word)\n",
    "                        if cur_idx != last_word and cur_idx != last_word2:\n",
    "                            trigger_token_ids.append(cur_idx)\n",
    "                            new_sentence.append(word)\n",
    "                            last_word2 = last_word\n",
    "                            last_word = cur_idx\n",
    "\n",
    "                            if word in sentiment_words:\n",
    "                                contain_sentiment_word = True\n",
    "\n",
    "                    threshold = 0.89\n",
    "                    num_lim = 20\n",
    "                    s_str = glue.join(new_sentence)\n",
    "                    if not (s_str in sentence_list):\n",
    "                        accuracy = get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids)\n",
    "                        if accuracy < threshold:\n",
    "                            sentence_list.append(s_str)\n",
    "                            output_s.append((s_str, accuracy, contain_sentiment_word))\n",
    "\n",
    "                if len(output_s) > 0:\n",
    "                    all_output = all_output + output_s\n",
    "                update = False\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# use GPT2 for post selection.\n",
    "GPT2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "GPT2_model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "\n",
    "triggers = all_output\n",
    "select_fluent_trigger(triggers, GPT2_model, GPT2_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8656"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain LstmClassifier for IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, dataset):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(lazy_groups_of(iterator(dataset, shuffle=True), group_size=1), leave=True, position=0):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = move_to_device(batch[0], cuda_device=0)\n",
    "        tokens = batch['tokens']\n",
    "        label = batch['label']\n",
    "        \n",
    "        output = model(tokens, label)\n",
    "        \n",
    "        loss = output['loss'] # criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = model.get_metrics()['accuracy']\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36267it [49:12, 12.02it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "50477it [1:08:31, 12.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1f2b9f45c4f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     start_time = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-16d3b76d5b41>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, dataset)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# criterion(predictions, batch.label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hddraid1/hpeng/ARAE/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hddraid1/hpeng/universal_attack_natural_trigger/sst/sst_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, label)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_field_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mencoder_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hddraid1/hpeng/ARAE/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hddraid1/hpeng/ARAE/venv/lib/python3.6/site-packages/allennlp/modules/seq2vec_encoders/pytorch_seq2vec_wrapper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, mask, hidden_state)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_and_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# Deal with the fact the LSTM state is a tuple of (state, memory).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hddraid1/hpeng/ARAE/venv/lib/python3.6/site-packages/allennlp/modules/encoder_base.py\u001b[0m in \u001b[0;36msort_and_run_forward\u001b[0;34m(self, module, inputs, mask, hidden_state)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Actually call the module on the sorted PackedSequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_sequence_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hddraid1/hpeng/ARAE/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hddraid1/hpeng/ARAE/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 562\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model.get_metrics(reset=True)\n",
    "iterator = BucketIterator(batch_size=50, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(sst_vocab)\n",
    "# get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids=None)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# train_loss, train_acc = train(model, iterator, optimizer)\n",
    "N_EPOCHS = 5\n",
    "\n",
    "# best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "#     start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, iterator, optimizer, train_data[::2])\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     end_time = time.time()\n",
    "\n",
    "#     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'imdb-lstm_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LstmClassifier(\n",
       "  (word_embeddings): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (encoder): PytorchSeq2VecWrapper(\n",
       "    (_module): LSTM(300, 512, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (loss_function): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LstmClassifier(word_embeddings, encoder, sst_vocab)\n",
    "model.load_state_dict(torch.load('imdb-lstm_model.pt'))\n",
    "embedding_weight = get_embedding_weight(model)\n",
    "model.train().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
