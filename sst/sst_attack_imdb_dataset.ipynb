{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from transformers import *\n",
    "import torch.optim as optim\n",
    "from sst_classifier import LstmClassifier\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "from allennlp.data.dataset_readers.stanford_sentiment_tree_bank import StanfordSentimentTreeBankDatasetReader\n",
    "from allennlp.data.iterators import BucketIterator, BasicIterator\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders.embedding import _read_pretrained_embeddings_file\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.nn.util import get_text_field_mask, move_to_device\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.gradcheck import zero_gradients\n",
    "import torch.nn.functional as F\n",
    "sys.path.append('../')\n",
    "from ARAE_utils import Seq2Seq, MLP_D, MLP_G, generate\n",
    "from utils import get_embedding_weight, get_accuracy\n",
    "from attack_util import project_noise, one_hot_prob, GPT2_LM_loss, select_fluent_trigger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ARAE_models(load_path, args):\n",
    "    # function to load ARAE model.\n",
    "    if not os.path.exists(load_path):\n",
    "        print('Please download the pretrained ARAE model first')\n",
    "        \n",
    "    ARAE_args = json.load(open(os.path.join(load_path, 'options.json'), 'r'))\n",
    "    vars(args).update(ARAE_args)\n",
    "    autoencoder = Seq2Seq(emsize=args.emsize,\n",
    "                          nhidden=args.nhidden,\n",
    "                          ntokens=args.ntokens,\n",
    "                          nlayers=args.nlayers,\n",
    "                          noise_r=args.noise_r,\n",
    "                          hidden_init=args.hidden_init,\n",
    "                          dropout=args.dropout,\n",
    "                          gpu=args.cuda)\n",
    "    gan_gen = MLP_G(ninput=args.z_size, noutput=args.nhidden, layers=args.arch_g)\n",
    "    gan_disc = MLP_D(ninput=args.nhidden, noutput=1, layers=args.arch_d)\n",
    "\n",
    "    autoencoder = autoencoder.cuda()\n",
    "    gan_gen = gan_gen.cuda()\n",
    "    gan_disc = gan_disc.cuda()\n",
    "\n",
    "    ARAE_word2idx = json.load(open(os.path.join(args.load_path, 'vocab.json'), 'r'))\n",
    "    ARAE_idx2word = {v: k for k, v in ARAE_word2idx.items()}\n",
    "\n",
    "    print('Loading models from {}'.format(args.load_path))\n",
    "    loaded = torch.load(os.path.join(args.load_path, \"model.pt\"))\n",
    "    autoencoder.load_state_dict(loaded.get('ae'))\n",
    "    gan_gen.load_state_dict(loaded.get('gan_g'))\n",
    "    gan_disc.load_state_dict(loaded.get('gan_d'))\n",
    "    return ARAE_args, ARAE_idx2word, ARAE_word2idx, autoencoder, gan_gen, gan_disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--load_path', type=str, default='../../ARAE/sentiment_classifier/oneb_pretrained',\n",
    "                    help='directory to load models from')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--sample', action='store_true',\n",
    "                    help='sample when decoding for generation')\n",
    "parser.add_argument('--len_lim', type=int, default=5,\n",
    "                    help='maximum length of sentence')\n",
    "parser.add_argument('--r_lim', type=float, default=1,\n",
    "                    help='lim of radius of z')\n",
    "parser.add_argument('--sentiment_path', type=str, default='./opinion_lexicon_English',\n",
    "                    help='directory to load sentiment word from')\n",
    "parser.add_argument('--z_seed', type=float, default=6.,\n",
    "                    help='noise seed for z')\n",
    "parser.add_argument('--avoid_l', type=int, default=4,\n",
    "                    help='length to avoid repeated pattern')\n",
    "parser.add_argument('--lr', type=float, default=1e3,\n",
    "                    help='learn rate')\n",
    "parser.add_argument('--attack_class', type=str, default='1',\n",
    "                    help='the class label to attack')\n",
    "parser.add_argument('--noise_n', type=int, default=256,\n",
    "                    help='number of generated noise vectors')\n",
    "parser.add_argument('--tot_runs', type=int, default=1,\n",
    "                    help='number of attack runs')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ARAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# initialize ARAE model.\n",
    "ARAE_args, ARAE_idx2word, ARAE_word2idx, autoencoder, gan_gen, gan_disc = load_ARAE_models(args.load_path, args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained sentiment analysis model.\n",
    "word_embedding_dim = 300\n",
    "EMBEDDING_TYPE = \"w2v\"\n",
    "vocab_path = \"./model_dir/\" + EMBEDDING_TYPE + \"_\" + \"vocab\"\n",
    "\n",
    "sst_vocab = Vocabulary.from_files(vocab_path)\n",
    "weight = torch.load('sst_emb_weight.pt')\n",
    "token_embedding = Embedding(num_embeddings=sst_vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=word_embedding_dim,\n",
    "                            weight=weight,\n",
    "                            trainable=False)\n",
    "\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "encoder = PytorchSeq2VecWrapper(torch.nn.LSTM(word_embedding_dim,\n",
    "                                              hidden_size=512,\n",
    "                                              num_layers=2,\n",
    "                                              batch_first=True))\n",
    "\n",
    "model_path = \"./model_dir/\" + EMBEDDING_TYPE + \"_\" + \"model.th\"\n",
    "model = LstmClassifier(word_embeddings, encoder, sst_vocab)\n",
    "\n",
    "with open(model_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    f.close()\n",
    "embedding_weight = get_embedding_weight(model)\n",
    "model.train().cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ARAE word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arange ARAE word embedding in consistent with sst model.\n",
    "ARAE_weight_embedding = []\n",
    "for num in range(len(ARAE_idx2word)):\n",
    "    ARAE_weight_embedding.append(embedding_weight[sst_vocab.get_token_index(ARAE_idx2word[num])].numpy())\n",
    "ARAE_weight_embedding = torch.from_numpy(np.array(ARAE_weight_embedding)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove sentiment words from ARAE so that we won't use them to generate trivial attacks. Also, mask out the unkown words for SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### collect positive/negative sentences\n",
    "single_id_indexer = SingleIdTokenIndexer(lowercase_tokens=True)  # word tokenizer\n",
    "reader = StanfordSentimentTreeBankDatasetReader(granularity=\"2-class\",\n",
    "                                                token_indexers={\"tokens\": single_id_indexer})\n",
    "dev_data = reader.read('https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt')\n",
    "\n",
    "# For sentiment analysis, get rid of positive and negative.\n",
    "pos_path = os.path.join(args.sentiment_path, 'positive_words.txt')\n",
    "neg_path = os.path.join(args.sentiment_path, 'negative_words.txt')\n",
    "\n",
    "pos_words = list()\n",
    "with open(cached_path(pos_path), \"r\") as data_file:\n",
    "    for line in data_file.readlines():\n",
    "        if line[0] != ';':\n",
    "            line = line.strip(\"\\n\")\n",
    "            if not line:\n",
    "                continue\n",
    "            else:\n",
    "                pos_words.append(line)\n",
    "\n",
    "neg_words = list()\n",
    "with open(cached_path(neg_path), \"r\", encoding = \"ISO-8859-1\") as data_file:\n",
    "    for line in data_file.readlines():\n",
    "        if line[0] != ';':\n",
    "            line = line.strip(\"\\n\")\n",
    "            if not line:\n",
    "                continue\n",
    "            else:\n",
    "                neg_words.append(line)\n",
    "\n",
    "my_list = ['missing', 'rapes']\n",
    "sentiment_words = pos_words + neg_words + my_list\n",
    "\n",
    "mask_word_ARAE = list()\n",
    "for word in sentiment_words:\n",
    "    if word in ARAE_word2idx:\n",
    "        mask_word_ARAE.append(ARAE_word2idx[word])\n",
    "\n",
    "# mask words that are unknown for sentiment words.\n",
    "ARAE_words = list(ARAE_word2idx.keys())\n",
    "for word in ARAE_words:\n",
    "    if sst_vocab.get_token_index(word) == 1:\n",
    "        mask_word_ARAE.append(ARAE_word2idx[word])\n",
    "mask_word_ARAE = list(set(mask_word_ARAE))\n",
    "sent_word_ARAE = np.array(mask_word_ARAE)\n",
    "\n",
    "mask_sentiment_logits = np.zeros((1, 1, len(ARAE_words)))\n",
    "mask_sentiment_logits[:, :, sent_word_ARAE] = -float(\"Inf\")\n",
    "mask_sentiment_logits = torch.tensor(mask_sentiment_logits, requires_grad=False)\n",
    "mask_sentiment_logits = mask_sentiment_logits.float().cuda()\n",
    "mask_sentiment = mask_sentiment_logits[0]\n",
    "\n",
    "dataset_label_filter = args.attack_class\n",
    "targeted_dev_data = []\n",
    "\n",
    "for instance in dev_data:\n",
    "    if instance['label'].label == dataset_label_filter:\n",
    "        targeted_dev_data.append(instance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to generate universal trigger to attack the sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_metrics(reset=True)\n",
    "\n",
    "iterator = BucketIterator(batch_size=256, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(sst_vocab)\n",
    "get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids=None)\n",
    "\n",
    "\n",
    "maxlen = args.len_lim\n",
    "# initialize noise\n",
    "noise_n = args.noise_n  # this should be a factor of batch_size\n",
    "tot_runs = args.tot_runs\n",
    "n_repeat = 1\n",
    "\n",
    "\n",
    "r_threshold = args.r_lim\n",
    "step_bound = r_threshold / 100\n",
    "max_iterations = 1000\n",
    "\n",
    "patience_lim = 3\n",
    "patience = 0 \n",
    "max_trial = 3\n",
    "all_output = list()\n",
    "log_loss = int(1e2)\n",
    "\n",
    "for tmp in range(tot_runs):\n",
    "    model.get_metrics(reset=True)\n",
    "    step_size = args.lr\n",
    "    step_scale = 0.1 \n",
    "    patience = 0\n",
    "    old_noise = None\n",
    "    old_loss = float('-Inf')\n",
    "    loss_list = list()\n",
    "    update = False\n",
    "    i_trial = 0\n",
    "\n",
    "    torch.manual_seed(args.z_seed + tmp)\n",
    "    print('z_seed:{}'.format(args.z_seed + tmp))\n",
    "    noise = torch.randn(noise_n, ARAE_args['z_size'], requires_grad=True).cuda()\n",
    "    noise = Variable(noise, requires_grad=True)\n",
    "    start_noise_data = noise.data.clone()\n",
    "    iter = 0\n",
    "    for batch in lazy_groups_of(iterator(targeted_dev_data, num_epochs=int(5e5), shuffle=True), group_size=1):\n",
    "        # evaluate_batch(model, batch, trigger_token_ids, snli)\n",
    "        # generate sentence with ARAE, output the word embedding instead of index.\n",
    "        batch = move_to_device(batch[0], cuda_device=0)\n",
    "        tokens = batch['tokens']\n",
    "        label = batch['label']\n",
    "\n",
    "        model.train()\n",
    "        autoencoder.train()\n",
    "        gan_gen.eval()\n",
    "        gan_disc.eval()\n",
    "\n",
    "        hidden = gan_gen(noise)\n",
    "\n",
    "\n",
    "        max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                             mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "        decoded = torch.stack(decoded, dim=1).float()\n",
    "        if n_repeat > 1:\n",
    "            decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "        decoded_prob = F.softmax(decoded, dim=-1)\n",
    "        decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "        out_emb = torch.matmul(decoded_prob, ARAE_weight_embedding)\n",
    "        output = model.forward_with_trigger(out_emb, tokens, label)\n",
    "\n",
    "        loss = output[\"loss\"]\n",
    "        iter += 1\n",
    "\n",
    "        loss_list.append(output[\"loss\"].item())\n",
    "        zero_gradients(noise)\n",
    "        loss.backward()\n",
    "\n",
    "        noise_diff = step_size * noise.grad.data\n",
    "        noise_diff = project_noise(noise_diff, r_threshold=step_bound)\n",
    "\n",
    "        noise.data = noise.data + noise_diff\n",
    "\n",
    "        whole_diff = noise.data - start_noise_data\n",
    "        whole_diff = project_noise(whole_diff, r_threshold=r_threshold)\n",
    "        noise.data = start_noise_data + whole_diff\n",
    "\n",
    "        if iter % log_loss == 0:\n",
    "            cur_loss = np.mean(loss_list)\n",
    "            print('current iter:{}'.format(iter))\n",
    "            print('current loss:{}'.format(cur_loss))\n",
    "\n",
    "            loss_list = list()\n",
    "            if cur_loss > old_loss:\n",
    "                patience = 0\n",
    "                old_loss = cur_loss\n",
    "                old_noise = noise.data.clone()\n",
    "                update = True\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "            print('current patience:{}'.format(patience))\n",
    "            print('\\n')\n",
    "\n",
    "            if patience >= patience_lim:\n",
    "                patience = 0\n",
    "                step_size *= step_scale\n",
    "                noise.data = old_noise\n",
    "                print('current step size:{}'.format(step_size))\n",
    "                i_trial += 1\n",
    "                print('current trial:{}'.format(i_trial))\n",
    "                print('\\n')\n",
    "\n",
    "        if i_trial >= max_trial or iter >= max_iterations:\n",
    "            if update:\n",
    "                with torch.no_grad():\n",
    "                    noise_new = torch.ones(noise_n, ARAE_args['z_size'], requires_grad=False).cuda()\n",
    "                    noise_new.data = old_noise\n",
    "                    hidden = gan_gen(noise_new)  # [:1, :]\n",
    "                    max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                                         mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "                    decoded = torch.stack(decoded, dim=1).float()\n",
    "                    if n_repeat > 1:\n",
    "                        decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "                    decoded_prob = F.softmax(decoded, dim=-1)\n",
    "                    decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "\n",
    "                sen_idxs = torch.argmax(decoded_prob, dim=2)\n",
    "                sen_idxs = sen_idxs.cpu().numpy()\n",
    "\n",
    "                output_s = list()\n",
    "                glue = ' '\n",
    "                sentence_list = list()\n",
    "                for ss in sen_idxs:\n",
    "                    sentence = [ARAE_idx2word[s] for s in ss]\n",
    "                    trigger_token_ids = list()\n",
    "                    last_word = None\n",
    "                    last_word2 = None\n",
    "                    contain_sentiment_word = False\n",
    "                    new_sentence = list()\n",
    "                    for word in sentence:\n",
    "                        cur_idx = sst_vocab.get_token_index(word)\n",
    "                        if cur_idx != last_word and cur_idx != last_word2:\n",
    "                            trigger_token_ids.append(cur_idx)\n",
    "                            new_sentence.append(word)\n",
    "                            last_word2 = last_word\n",
    "                            last_word = cur_idx\n",
    "\n",
    "                            if word in sentiment_words:\n",
    "                                contain_sentiment_word = True\n",
    "\n",
    "                    threshold = 0.5\n",
    "                    num_lim = 20\n",
    "                    s_str = glue.join(new_sentence)\n",
    "                    if not (s_str in sentence_list):\n",
    "                        accuracy = get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids)\n",
    "                        if accuracy < threshold:\n",
    "                            sentence_list.append(s_str)\n",
    "                            output_s.append((s_str, accuracy, contain_sentiment_word))\n",
    "\n",
    "                if len(output_s) > 0:\n",
    "                    all_output = all_output + output_s\n",
    "                update = False\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# use GPT2 for post selection.\n",
    "GPT2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "GPT2_model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "\n",
    "triggers = all_output\n",
    "select_fluent_trigger(triggers, GPT2_model, GPT2_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the algorithm transferability: \n",
    "### Use the same classifier, but a different dataset (IMDB dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import logging\n",
    "\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from itertools import chain\n",
    "\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.fields import LabelField, TextField, Field\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Tokenizer, WordTokenizer\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@DatasetReader.register('imdb')\n",
    "class ImdbDatasetReader(DatasetReader):\n",
    "\n",
    "    TAR_URL = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    TRAIN_DIR = 'aclImdb/train'\n",
    "    TEST_DIR = 'aclImdb/test'\n",
    "\n",
    "    def __init__(self,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 lazy: bool = False) -> None:\n",
    "        super().__init__(lazy=lazy)\n",
    "\n",
    "        self._tokenizer = tokenizer or WordTokenizer()\n",
    "        self._token_indexers = token_indexers or {'tokens': SingleIdTokenIndexer()}\n",
    "\n",
    "    @overrides\n",
    "    def _read(self, file_path):\n",
    "        tar_path = cached_path(self.TAR_URL)\n",
    "        tf = tarfile.open(tar_path, 'r')\n",
    "        cache_dir = Path(osp.dirname(tar_path))\n",
    "        if not (cache_dir / self.TRAIN_DIR).exists() and not (cache_dir / self.TEST_DIR).exists():\n",
    "            tf.extractall(cache_dir)\n",
    "\n",
    "        if file_path == 'train':\n",
    "            pos_dir = osp.join(self.TRAIN_DIR, 'pos')\n",
    "            neg_dir = osp.join(self.TRAIN_DIR, 'neg')\n",
    "        elif file_path == 'test':\n",
    "            pos_dir = osp.join(self.TEST_DIR, 'pos')\n",
    "            neg_dir = osp.join(self.TEST_DIR, 'neg')\n",
    "        else:\n",
    "            raise ValueError(f\"only 'train' and 'test' are valid for 'file_path', but '{file_path}' is given.\")\n",
    "        path = chain(Path(cache_dir.joinpath(pos_dir)).glob('*.txt'),\n",
    "                     Path(cache_dir.joinpath(neg_dir)).glob('*.txt'))\n",
    "\n",
    "        for p in path:\n",
    "            yield self.text_to_instance(p.read_text(), 0 if 'pos' in str(p) else 1)\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, string: str, label: int) -> Instance:\n",
    "        fields: Dict[str, Field] = {}\n",
    "        tokens = self._tokenizer.tokenize(string)\n",
    "        fields['tokens'] = TextField(tokens, self._token_indexers)\n",
    "        fields['label'] = LabelField(label, skip_indexing=True)\n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_id_indexer = SingleIdTokenIndexer(lowercase_tokens=True)  # word tokenizer\n",
    "reader = ImdbDatasetReader(token_indexers={\"tokens\": single_id_indexer})\n",
    "train_data = reader.read('train')\n",
    "test_data = reader.read('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View the instances of IMDB dataset; train and test data have both 250000 instances, \n",
    "## first half of data (0~12499) has label 0, and the rest has label 1\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment classification for IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without attack, measure accuracy for positive class (label=0)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, train_data[0:12500][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without attack, measure accuracy for positive class (label=1)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, train_data[12500:][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without attack, measure accuracy for positive class (label=0)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, test_data[0:12500][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without attack, measure accuracy for positive class (label=1)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, test_data[12500:][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Trigger Attack with IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect target dataset\n",
    "from tqdm import tqdm\n",
    "downsample = True\n",
    "dataset_label_filter = args.attack_class\n",
    "targeted_dev_data = []\n",
    "count = 0\n",
    "for instance in tqdm(test_data, leave=True, position=0):\n",
    "    if str(instance['label'].label) == dataset_label_filter:\n",
    "        targeted_dev_data.append(instance)\n",
    "        count += 1\n",
    "print(count)\n",
    "if downsample:\n",
    "    downsample_rate = 10\n",
    "    targeted_dev_data = targeted_dev_data[::downsample_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_metrics(reset=True)\n",
    "\n",
    "iterator = BucketIterator(batch_size=256, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(sst_vocab)\n",
    "get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = args.len_lim + 1\n",
    "# initialize noise\n",
    "noise_n = args.noise_n  # this should be a factor of batch_size\n",
    "tot_runs = args.tot_runs\n",
    "n_repeat = 1\n",
    "\n",
    "\n",
    "r_threshold = args.r_lim\n",
    "step_bound = r_threshold / 100\n",
    "max_iterations = 1000\n",
    "\n",
    "patience_lim = 3\n",
    "patience = 0 \n",
    "max_trial = 3\n",
    "all_output = list()\n",
    "log_loss = int(1e2)\n",
    "\n",
    "for tmp in range(tot_runs):\n",
    "    model.get_metrics(reset=True)\n",
    "    step_size = args.lr \n",
    "    step_scale = 0.1 \n",
    "    patience = 0\n",
    "    old_noise = None\n",
    "    old_loss = float('-Inf')\n",
    "    loss_list = list()\n",
    "    update = False\n",
    "    i_trial = 0\n",
    "\n",
    "    torch.manual_seed(args.z_seed + tmp)\n",
    "    print('z_seed:{}'.format(args.z_seed + tmp))\n",
    "    noise = torch.randn(noise_n, ARAE_args['z_size'], requires_grad=True).cuda()\n",
    "    noise = Variable(noise, requires_grad=True)\n",
    "    start_noise_data = noise.data.clone()\n",
    "    iter = 0\n",
    "    for batch in lazy_groups_of(iterator(targeted_dev_data, num_epochs=int(5e5), shuffle=True), group_size=1):\n",
    "        # evaluate_batch(model, batch, trigger_token_ids, snli)\n",
    "        # generate sentence with ARAE, output the word embedding instead of index.\n",
    "        batch = move_to_device(batch[0], cuda_device=0)\n",
    "        tokens = batch['tokens']\n",
    "        label = batch['label']\n",
    "        \n",
    "        model.train()\n",
    "        autoencoder.train()\n",
    "        gan_gen.eval()\n",
    "        gan_disc.eval()\n",
    "\n",
    "        hidden = gan_gen(noise)\n",
    "\n",
    "\n",
    "        max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                             mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "        decoded = torch.stack(decoded, dim=1).float()\n",
    "        if n_repeat > 1:\n",
    "            decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "        decoded_prob = F.softmax(decoded, dim=-1)\n",
    "        decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "        out_emb = torch.matmul(decoded_prob, ARAE_weight_embedding)\n",
    "        output = model.forward_with_trigger(out_emb, tokens, label)\n",
    "\n",
    "        loss = output[\"loss\"]\n",
    "        iter += 1\n",
    "\n",
    "        loss_list.append(output[\"loss\"].item())\n",
    "        zero_gradients(noise)\n",
    "        loss.backward()\n",
    "\n",
    "        noise_diff = step_size * noise.grad.data\n",
    "        noise_diff = project_noise(noise_diff, r_threshold=step_bound)\n",
    "\n",
    "        noise.data = noise.data + noise_diff\n",
    "\n",
    "        whole_diff = noise.data - start_noise_data\n",
    "        whole_diff = project_noise(whole_diff, r_threshold=r_threshold)\n",
    "        noise.data = start_noise_data + whole_diff\n",
    "\n",
    "        if iter % log_loss == 0:\n",
    "            cur_loss = np.mean(loss_list)\n",
    "            print('current iter:{}'.format(iter))\n",
    "            print('current loss:{}'.format(cur_loss))\n",
    "\n",
    "            loss_list = list()\n",
    "            if cur_loss > old_loss:\n",
    "                patience = 0\n",
    "                old_loss = cur_loss\n",
    "                old_noise = noise.data.clone()\n",
    "                update = True\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "            print('current patience:{}'.format(patience))\n",
    "            print('\\n')\n",
    "\n",
    "            if patience >= patience_lim:\n",
    "                patience = 0\n",
    "                step_size *= step_scale\n",
    "                noise.data = old_noise\n",
    "                print('current step size:{}'.format(step_size))\n",
    "                i_trial += 1\n",
    "                print('current trial:{}'.format(i_trial))\n",
    "                print('\\n')\n",
    "\n",
    "        if i_trial >= max_trial or iter >= max_iterations:\n",
    "            if update:\n",
    "                with torch.no_grad():\n",
    "                    noise_new = torch.ones(noise_n, ARAE_args['z_size'], requires_grad=False).cuda()\n",
    "                    noise_new.data = old_noise\n",
    "                    hidden = gan_gen(noise_new)  # [:1, :]\n",
    "                    max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                                         mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "                    decoded = torch.stack(decoded, dim=1).float()\n",
    "                    if n_repeat > 1:\n",
    "                        decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "                    decoded_prob = F.softmax(decoded, dim=-1)\n",
    "                    decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "\n",
    "                sen_idxs = torch.argmax(decoded_prob, dim=2)\n",
    "                sen_idxs = sen_idxs.cpu().numpy()\n",
    "\n",
    "                output_s = list()\n",
    "                glue = ' '\n",
    "                sentence_list = list()\n",
    "                for ss in sen_idxs:\n",
    "                    sentence = [ARAE_idx2word[s] for s in ss]\n",
    "                    trigger_token_ids = list()\n",
    "                    last_word = None\n",
    "                    last_word2 = None\n",
    "                    contain_sentiment_word = False\n",
    "                    new_sentence = list()\n",
    "                    for word in sentence:\n",
    "                        cur_idx = sst_vocab.get_token_index(word)\n",
    "                        if cur_idx != last_word and cur_idx != last_word2:\n",
    "                            trigger_token_ids.append(cur_idx)\n",
    "                            new_sentence.append(word)\n",
    "                            last_word2 = last_word\n",
    "                            last_word = cur_idx\n",
    "\n",
    "                            if word in sentiment_words:\n",
    "                                contain_sentiment_word = True\n",
    "\n",
    "                    threshold = 0.5\n",
    "                    num_lim = 20\n",
    "                    s_str = glue.join(new_sentence)\n",
    "                    if not (s_str in sentence_list):\n",
    "                        accuracy = get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids)\n",
    "                        if accuracy < threshold:\n",
    "                            sentence_list.append(s_str)\n",
    "                            output_s.append((s_str, accuracy, contain_sentiment_word))\n",
    "\n",
    "                if len(output_s) > 0:\n",
    "                    all_output = all_output + output_s\n",
    "                update = False\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# use GPT2 for post selection.\n",
    "GPT2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "GPT2_model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "\n",
    "triggers = all_output\n",
    "select_fluent_trigger(triggers, GPT2_model, GPT2_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain LstmClassifier for IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, dataset):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(lazy_groups_of(iterator(dataset, shuffle=True), group_size=1), leave=True, position=0):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = move_to_device(batch[0], cuda_device=0)\n",
    "        tokens = batch['tokens']\n",
    "        label = batch['label']\n",
    "        \n",
    "        output = model(tokens, label)\n",
    "        \n",
    "        loss = output['loss'] # criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = model.get_metrics()['accuracy']\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack the retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmClassifier(word_embeddings, encoder, sst_vocab)\n",
    "model.load_state_dict(torch.load('imdb-lstm_model.pt'))\n",
    "embedding_weight = get_embedding_weight(model)\n",
    "model.train().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without attack, measure accuracy for positive class (label=0)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, train_data[0:12500][::downsample_rate], sst_vocab, trigger_token_ids=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without attack, measure accuracy for positive class (label=1)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, train_data[12500:][::downsample_rate], sst_vocab, trigger_token_ids=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without attack, measure accuracy for positive class (label=0)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, test_data[0:12500][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without attack, measure accuracy for positive class (label=1)\n",
    "## Since the data size is large, here we subsample the dataset.\n",
    "# downsample_rate = 10\n",
    "get_accuracy(model, test_data[12500:][::downsample_rate], sst_vocab, trigger_token_ids=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect target dataset\n",
    "from tqdm import tqdm\n",
    "downsample = True\n",
    "dataset_label_filter = args.attack_class\n",
    "targeted_dev_data = []\n",
    "count = 0\n",
    "for instance in tqdm(test_data, leave=True, position=0):\n",
    "    if str(instance['label'].label) == dataset_label_filter:\n",
    "        targeted_dev_data.append(instance)\n",
    "        count += 1\n",
    "print(count)\n",
    "if downsample:\n",
    "    downsample_rate = 10\n",
    "    targeted_dev_data = targeted_dev_data[::downsample_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_metrics(reset=True)\n",
    "\n",
    "iterator = BucketIterator(batch_size=256, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "iterator.index_with(sst_vocab)\n",
    "get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = args.len_lim + 1\n",
    "# initialize noise\n",
    "noise_n = args.noise_n  # this should be a factor of batch_size\n",
    "tot_runs = args.tot_runs\n",
    "n_repeat = 1\n",
    "\n",
    "\n",
    "r_threshold = args.r_lim\n",
    "step_bound = r_threshold / 100\n",
    "max_iterations = 1000\n",
    "\n",
    "patience_lim = 3\n",
    "patience = 0 \n",
    "max_trial = 3\n",
    "all_output = list()\n",
    "log_loss = int(1e2)\n",
    "\n",
    "for tmp in range(tot_runs):\n",
    "    model.get_metrics(reset=True)\n",
    "    step_size = args.lr \n",
    "    step_scale = 0.1 \n",
    "    patience = 0\n",
    "    old_noise = None\n",
    "    old_loss = float('-Inf')\n",
    "    loss_list = list()\n",
    "    update = False\n",
    "    i_trial = 0\n",
    "\n",
    "    torch.manual_seed(args.z_seed + tmp)\n",
    "    print('z_seed:{}'.format(args.z_seed + tmp))\n",
    "    noise = torch.randn(noise_n, ARAE_args['z_size'], requires_grad=True).cuda()\n",
    "    noise = Variable(noise, requires_grad=True)\n",
    "    start_noise_data = noise.data.clone()\n",
    "    iter = 0\n",
    "    for batch in lazy_groups_of(iterator(targeted_dev_data, num_epochs=int(5e5), shuffle=True), group_size=1):\n",
    "        # evaluate_batch(model, batch, trigger_token_ids, snli)\n",
    "        # generate sentence with ARAE, output the word embedding instead of index.\n",
    "        batch = move_to_device(batch[0], cuda_device=0)\n",
    "        tokens = batch['tokens']\n",
    "        label = batch['label']\n",
    "        \n",
    "        model.train()\n",
    "        autoencoder.train()\n",
    "        gan_gen.eval()\n",
    "        gan_disc.eval()\n",
    "\n",
    "        hidden = gan_gen(noise)\n",
    "\n",
    "\n",
    "        max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                             mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "        decoded = torch.stack(decoded, dim=1).float()\n",
    "        if n_repeat > 1:\n",
    "            decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "        decoded_prob = F.softmax(decoded, dim=-1)\n",
    "        decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "        out_emb = torch.matmul(decoded_prob, ARAE_weight_embedding)\n",
    "        output = model.forward_with_trigger(out_emb, tokens, label)\n",
    "\n",
    "        loss = output[\"loss\"]\n",
    "        iter += 1\n",
    "\n",
    "        loss_list.append(output[\"loss\"].item())\n",
    "        zero_gradients(noise)\n",
    "        loss.backward()\n",
    "\n",
    "        noise_diff = step_size * noise.grad.data\n",
    "        noise_diff = project_noise(noise_diff, r_threshold=step_bound)\n",
    "\n",
    "        noise.data = noise.data + noise_diff\n",
    "\n",
    "        whole_diff = noise.data - start_noise_data\n",
    "        whole_diff = project_noise(whole_diff, r_threshold=r_threshold)\n",
    "        noise.data = start_noise_data + whole_diff\n",
    "\n",
    "        if iter % log_loss == 0:\n",
    "            cur_loss = np.mean(loss_list)\n",
    "            print('current iter:{}'.format(iter))\n",
    "            print('current loss:{}'.format(cur_loss))\n",
    "\n",
    "            loss_list = list()\n",
    "            if cur_loss > old_loss:\n",
    "                patience = 0\n",
    "                old_loss = cur_loss\n",
    "                old_noise = noise.data.clone()\n",
    "                update = True\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "            print('current patience:{}'.format(patience))\n",
    "            print('\\n')\n",
    "\n",
    "            if patience >= patience_lim:\n",
    "                patience = 0\n",
    "                step_size *= step_scale\n",
    "                noise.data = old_noise\n",
    "                print('current step size:{}'.format(step_size))\n",
    "                i_trial += 1\n",
    "                print('current trial:{}'.format(i_trial))\n",
    "                print('\\n')\n",
    "\n",
    "        if i_trial >= max_trial or iter >= max_iterations:\n",
    "            if update:\n",
    "                with torch.no_grad():\n",
    "                    noise_new = torch.ones(noise_n, ARAE_args['z_size'], requires_grad=False).cuda()\n",
    "                    noise_new.data = old_noise\n",
    "                    hidden = gan_gen(noise_new)  # [:1, :]\n",
    "                    max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
    "                                                                         mask=mask_sentiment, avoid_l=args.avoid_l)\n",
    "\n",
    "                    decoded = torch.stack(decoded, dim=1).float()\n",
    "                    if n_repeat > 1:\n",
    "                        decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "                    decoded_prob = F.softmax(decoded, dim=-1)\n",
    "                    decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "\n",
    "                sen_idxs = torch.argmax(decoded_prob, dim=2)\n",
    "                sen_idxs = sen_idxs.cpu().numpy()\n",
    "\n",
    "                output_s = list()\n",
    "                glue = ' '\n",
    "                sentence_list = list()\n",
    "                for ss in sen_idxs:\n",
    "                    sentence = [ARAE_idx2word[s] for s in ss]\n",
    "                    trigger_token_ids = list()\n",
    "                    last_word = None\n",
    "                    last_word2 = None\n",
    "                    contain_sentiment_word = False\n",
    "                    new_sentence = list()\n",
    "                    for word in sentence:\n",
    "                        cur_idx = sst_vocab.get_token_index(word)\n",
    "                        if cur_idx != last_word and cur_idx != last_word2:\n",
    "                            trigger_token_ids.append(cur_idx)\n",
    "                            new_sentence.append(word)\n",
    "                            last_word2 = last_word\n",
    "                            last_word = cur_idx\n",
    "\n",
    "                            if word in sentiment_words:\n",
    "                                contain_sentiment_word = True\n",
    "\n",
    "                    threshold = 0.5\n",
    "                    num_lim = 20\n",
    "                    s_str = glue.join(new_sentence)\n",
    "                    if not (s_str in sentence_list):\n",
    "                        accuracy = get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids)\n",
    "                        if accuracy < threshold:\n",
    "                            sentence_list.append(s_str)\n",
    "                            output_s.append((s_str, accuracy, contain_sentiment_word))\n",
    "\n",
    "                if len(output_s) > 0:\n",
    "                    all_output = all_output + output_s\n",
    "                update = False\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# use GPT2 for post selection.\n",
    "GPT2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "GPT2_model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "\n",
    "triggers = all_output\n",
    "select_fluent_trigger(triggers, GPT2_model, GPT2_tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
